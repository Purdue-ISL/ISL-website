<template>
  <div id="doc" class="bg-[var(--primary-color)] bg-img min-h-screen">
    <div class="limit-width">
      <HeaderNav />
    </div>
    <PageHeader title="Projects" />
    <div class="limit-width">
      <div class="w-[96%] mx-auto"></div>
      <h1 class="subpages-title">
        Next Generation Multi-Perspective Video Delivery at Internet Scale
      </h1>
      <SubPageNav
        v-bind:data="[
          ['Description', 'des'],
          ['Publications', 'pub'],
          ['People', 'ppl'],
        ]"
      />

      <div id="des" class="subpages-section-container-div">
        <div class="subpages-section-title-container-div">
          <h1 class="subpages-section-title">Description</h1>
        </div>
        <div class="subpages-section-content">
          <p>
            The success of streaming video has generated interest in newer forms
            of multi-perspective video content, such as those generated by
            360-degree cameras, multi-angle camera arrays, or light-field
            cameras. The immersive experience provided by these cameras can
            enhance user satisfaction in domains including sports, training
            (e.g., construction safety), and virtual exploration (e.g., college
            walkthroughs, historical sites). With content from these cameras,
            users do not just passively consume content, but may interactively
            traverse the content along many different paths from a perspective
            of their choice, with different users observing different
            perspectives of the same content. To support this at Internet-scale
            is challenging; client players must be able to switch perspectives
            with low latency, the perspectives may need to be generated on
            demand by video servers, and the infrastructure must support a
            variety of devices for capture and consumption of this content.
            <br /><br />

            This project explores architectural enhancements, algorithms, and
            techniques to deliver multi-perspective video at Internet-scale. It
            couples delivery optimization with video coding and human computer
            interaction. The project will develop interactivity abstractions by
            which content publishers can specify the range of perspectives users
            are permitted to choose from at each point in the video. The
            interactivity specified in a video will (i) drive perspective coding
            and novel dynamic perspective generation algorithms; (ii) enable
            infrastructure provisioning to meet Content Delivery Network (CDN)
            storage and cost constraints; and (iii) will guide adaptive
            perspective retrieval from CDN servers or from nearby caches.
            Finally, the project will explore methods to predict and guide user
            behavior to improve delivery quality based on user studies.
          </p>
        </div>
      </div>

      <div id="pub" class="subpages-section-container-div">
        <div class="subpages-section-title-container-div">
          <h1 class="subpages-section-title">Publications</h1>
        </div>
        <div class="subpages-section-content">
          <PublicationsPublication
            title="Dragonfly: Higher Perceptual Quality For Continuous 360° Video Playback"
            authors="Ehab Ghabashneh, Chandan Bothra, Ramesh Govindan, Antonio Ortega, and Sanjay Rao"
            conference="Proceedings of ACM Special Interest Group on Data Communications (SIGCOMM), 2023"
            paper="papers-pdf/dfly.pdf"
            slides="papers-pdf/Dragonfly-Sigcomm23_final.pptx"
            video="https://www.youtube.com/watch?v=FHyaGPMBV6c"
            github="https://github.com/Purdue-ISL/Dragonfly"
          />
          <PublicationsSeparator />
        </div>
      </div>

      <div id="ppl" class="subpages-section-container-div">
        <div class="subpages-section-title-container-div">
          <h1 class="subpages-section-title">Team</h1>
        </div>
        <div class="subpages-section-content">
          <div>
            <span class="font-bold text-xl">Faculty</span>
            <div class="text-lg pl-2">
              <ul class="gap-10">
                <li class="font-mono tracking-tighter">Prof. Sanjay Rao</li>
                <li class="font-mono tracking-tighter">Prof. Alex Quinn</li>
              </ul>
            </div>
          </div>
          <br />

          <div>
            <span class="font-bold text-xl">Students</span>
            <div class="text-lg pl-2">
              <ul class="gap-10">
                <li class="font-mono tracking-tighter">Ehab Ghabashneh</li>
                <li class="font-mono tracking-tighter">Chandan Bothra</li>
              </ul>
            </div>
          </div>
          <br />

          <div>
            <span class="font-bold text-xl">Collaborators</span>
            <div class="text-lg pl-2">
              <ul class="gap-10">
                <li>
                  <span class="font-mono tracking-tighter"
                    >Prof. Ramesh Govindan</span
                  >
                  <span> — University of Southern California</span>
                </li>
                <li>
                  <span class="font-mono tracking-tighter"
                    >Prof. Antonio Ortega</span
                  >
                  <span> — University of Southern California</span>
                </li>
              </ul>
            </div>
          </div>
          <br />
        </div>
      </div>
    </div>

    <div class="pb-[30px]"></div>
  </div>
</template>  
  
  
  
  
  
  
  <script type="module">
let projects_divs = [];
export default {
  beforeRouteEnter(to, from, next) {
    console.log(from);
    console.log(to);
    to.params.link = from;
    next();
  },
  methods: {
    overlap(element, threshold) {
      let topOverlap =
        (window.screen.height - element.getBoundingClientRect().top) /
        window.screen.height;
      if (topOverlap > threshold) {
        return true;
      }
      return false;
    },

    handleScroll() {
      var filtered = [];
      for (var idx in projects_divs) {
        if (this.overlap(projects_divs[idx], 0.1)) {
          projects_divs[idx].classList.toggle("show-up");
          filtered.push(idx);
        }
      }
      for (var idx in filtered) {
        delete projects_divs[filtered[idx]];
      }
      if (Object.keys(projects_divs).length == 0) {
        console.log("removed");
        window.removeEventListener("scroll", this.handleScroll);
      }
    },
  },
  mounted() {
    window.scrollTo(0, 0);
    projects_divs = [];
    let projects_divs_nodelist = document.querySelectorAll(
      ".subpages-section-container-div"
    );
    projects_divs_nodelist.forEach((projects_div) => {
      projects_divs.push(projects_div);
      if (projects_div.classList.contains("show-up")) {
        projects_div.classList.toggle("show-up");
      }
    });

    window.addEventListener("scroll", this.handleScroll);
    window.addEventListener("load", this.handleScroll);
    // in case height is small.
    this.handleScroll();
  },
};
</script>
  
  
  